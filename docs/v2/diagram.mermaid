graph TB
    subgraph "Input Layer"
        A[Input IDs] --> B[Word Embeddings<br/>Linear: vocab_size→1024]
        B --> C[Dropout 0.1]
    end
    
    subgraph "Recursive Loop x2 (Logical Depth = 24)"
        C --> D[Loop Start]
        
        subgraph "Hybrid Layers x12 - STABLE 6-LAYER PATTERN"
            D --> E[Dynamic Tanh Norm]
            
            subgraph "Mixer Block - Stable Pattern Cycle"
                E --> F{Layer Type<br/>Stable 6-Layer Pattern}
                
                F -->|"1,3: RetNet<br/>(Stability Anchors)"| G1[Multi-Scale Retention<br/>BitLinear QKV + Decay<br/>γ: 0.97 to 0.999]
                F -->|"2,5: Titan Attn<br/>(Proven Stable)"| G2[Standard Attention<br/>BitLinear QKV<br/>Scaled Dot-Product]
                F -->|"4: Mamba<br/>(Sandwiched)"| G3[Mamba SSM<br/>BitLinear<br/>Selective State Space]
                F -->|"6: ODE<br/>(End Position)"| G4[Neural ODE Attention<br/>RK4 Solver, 2 steps<br/>Lower LR: 5e-5]
                
                G1 --> H[Mixer Output]
                G2 --> H
                G3 --> H
                G4 --> H
            end
            
            H --> I[Residual + Dropout]
            I --> J[Dynamic Tanh Norm]
            
            subgraph "Sparse MoE Block (BitNet)"
                J --> K[Router: Linear<br/>1024→4 experts<br/>no bias]
                K --> L[Top-K Selection<br/>k=2 experts]
                
                subgraph "Expert Processing (4 Experts)"
                    L --> M[Expert 1: BitLinear<br/>1024→2048→1024 + SiLU]
                    L --> N[Expert 2: BitLinear<br/>1024→2048→1024 + SiLU]
                    L --> O[Expert 3: BitLinear<br/>1024→2048→1024 + SiLU]
                    L --> P[Expert 4: BitLinear<br/>1024→2048→1024 + SiLU]
                end
                
                M --> Q[Weighted Expert Sum]
                N --> Q
                O --> Q
                P --> Q
            end
            
            Q --> R[Residual + Dropout]
            R --> S[To Next Layer]
        end
        
        S --> T[Next Loop Iteration]
        T --> D
    end
    
    subgraph "Output Layer"
        S --> U[Final Dynamic Tanh Norm]
        U --> V[BitLinear Head<br/>1024→vocab_size]
        V --> W[Output Logits]
    end
    
    subgraph "Training Pipeline"
        W --> X[MLM Loss<br/>CrossEntropyLoss<br/>ignore_index=-100]
        X --> Y[AdamW Optimizer<br/>Component-specific LR<br/>betas= 0.9, 0.95]
        Y --> Z[Cosine LR Schedule<br/>10% Warmup<br/>1000 warmup steps]
    end
    
    subgraph "Checkpointing Strategy"
        Z --> CP1[Rolling Checkpoints<br/>Every 500 steps<br/>Keep last 3]
        Z --> CP2[Best Model Checkpoints<br/>Top K=2 by loss]
        Z --> CP3[Epoch Checkpoints<br/>End of each epoch]
    end
    
    subgraph "Safety & Monitoring"
        X --> NAN{NaN Detection<br/>Every step}
        NAN -->|NaN Found| STOP[Emergency Stop<br/>+ Debug Logs<br/>+ Emergency Checkpoint]
        NAN -->|OK| CSV[CSV Metrics Log<br/>loss, lr, acc, grad_norm<br/>gpu_memory, scaler_scale]
    end
    
    %% Layer Pattern Legend
    subgraph "Stable 6-Layer Pattern (×2 cycles = 12 layers)"
        LP1[1. RetNet] --> LP2[2. Titan Attn]
        LP2 --> LP3[3. RetNet]
        LP3 --> LP4[4. Mamba]
        LP4 --> LP5[5. Titan Attn]
        LP5 --> LP6[6. ODE]
        LP6 -.-> LP1
    end
    
    %% Styling
    style G1 fill:#e0f2f1,stroke:#00796b
    style G2 fill:#fce4ec,stroke:#c2185b
    style G3 fill:#fff3e0,stroke:#ef6c00
    style G4 fill:#e8eaf6,stroke:#3f51b5
    style K fill:#ffe1e1
    style M fill:#fff3e0
    style N fill:#fff3e0
    style O fill:#fff3e0
    style P fill:#fff3e0
    style V fill:#fff3e0
    style E fill:#e1bee7
    style J fill:#e1bee7
    style U fill:#e1bee7
    style NAN fill:#ffcdd2,stroke:#d32f2f
    style STOP fill:#f44336,stroke:#b71c1c,color:#fff
    style CSV fill:#c8e6c9,stroke:#388e3c
    style CP1 fill:#bbdefb,stroke:#1976d2
    style CP2 fill:#fff9c4,stroke:#fbc02d
    style LP1 fill:#e0f2f1
    style LP2 fill:#fce4ec
    style LP3 fill:#e0f2f1
    style LP4 fill:#fff3e0
    style LP5 fill:#fce4ec
    style LP6 fill:#e8eaf6